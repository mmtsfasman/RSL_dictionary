{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import os\n",
    "from model import *\n",
    "#entry, homograph, etymology, signs,  \n",
    "#import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_pickle(filename):\n",
    "    '''receives csv file, returns json '''\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as csvfile:\n",
    "        data = csv.DictReader(csvfile)\n",
    "    \n",
    "        if not os.path.exists('./database.pickle'):\n",
    "            open('database.txt','w+', encoding='utf-8')\n",
    "        \n",
    "    \n",
    "        to_add_to_bd = []\n",
    "\n",
    "        for row in data:\n",
    "            new_entry = entry()\n",
    "            new_entry.signs.append(sign(row['hamnosys'], [video(url=row['video'])]))\n",
    "            new_entry.homographs.append(homograph([lexical_unit(row['translation'])]))\n",
    "            new_entry.etymology = etymology(row['etymology'])\n",
    "            to_add_to_bd.append(new_entry)\n",
    "            if row['words_referred'] != '':\n",
    "                for word in row['words_referred'].split(','):\n",
    "                    new_entry.etymology.words_referred.append(gloss(word=word))\n",
    "\n",
    "\n",
    "        with open('database.pickle', 'wb') as outfile:\n",
    "            pickle.dump(to_add_to_bd, outfile)\n",
    "        \n",
    "        \n",
    "csv_to_pickle('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'translation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e5eac7b46c75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./database.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlus\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhomograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexical_units\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhomograph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhomographs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e5eac7b46c75>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./database.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlus\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhomograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexical_units\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhomograph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhomographs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'translation'"
     ]
    }
   ],
   "source": [
    "d = pickle.load(open(\"./database.pickle\", 'rb'))\n",
    "' '.join([lu for lu in [lus for lus in [homograph.lexical_units for homograph in d[0].homographs]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''x = entry()\n",
    "x.signs.append(sign('syahvbjnxl1528%', 'youtube.ru/signinRSL'))\n",
    "x.homographs.append(homograph([lexical_unit('Коала, сидящая на дереве', 'Сущ.', labels(region='Новосиб.'))]))\n",
    "s = pickle.dumps(x)\n",
    "\n",
    "s = pickle.loads(s)\n",
    "print(s)\n",
    "\n",
    "#x = lexical_unit('человек', 'N', labels('ru', 'разговорная речь'))\n",
    "#x.examples.append(example('http://123', 'человек залез на дерево', [gloss('залезть', 'http://залезть.com'), gloss('человек-на-дерево')]))\n",
    "#s = pickle.dumps(x)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://drive.google.com/open?id=0BxKi0m1pRr5VQzExMng1UXhMYnRYYU1UNzVLRk82LXhUcDFr\n"
     ]
    }
   ],
   "source": [
    "print(data[0].signs[0].videos[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('database.pickle', 'rb') as outfile:\n",
    "    data  = pickle.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Компаунд, произошедший из слияния слов ‘испуг’ и ‘ беспорядок’.', 'words_referred': ['испуг', ' беспорядок']}\n"
     ]
    }
   ],
   "source": [
    "print(data[7].etymology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "typing.TYPE_CHECKING = True\n",
    "def f(x: typing.List[str]) -> str:\n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pickle.load(open(\"./database.txt\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signs': [{'hamnosys': '\\ue009\\ue022\\ue03c\\ue044\\ue058\\ue082\\ue052\\ue058', 'video_urls': ['https://drive.google.com/open?id=0BxKi0m1pRr5VQzExMng1UXhMYnRYYU1UNzVLRk82LXhUcDFr'], 'labels': {'region': '', 'register': '', 'domain': '', 'style': ''}}], 'homographs': [{'lexical_units': [{'translation': 'человек', 'part_of_speech': [], 'labels': {'region': '', 'register': '', 'domain': '', 'style': ''}, 'examples': [], 'inflected_forms': []}]}], 'etymology': {'text': '', 'words_referred': []}, 'MWE': []}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support to pretty-print lists, tuples, & dictionaries recursively.\n",
      "\n",
      "Very simple, but useful, especially in debugging data structures.\n",
      "\n",
      "Classes\n",
      "-------\n",
      "\n",
      "PrettyPrinter()\n",
      "    Handle pretty-printing operations onto a stream using a configured\n",
      "    set of formatting parameters.\n",
      "\n",
      "Functions\n",
      "---------\n",
      "\n",
      "pformat()\n",
      "    Format a Python object into a pretty-printed representation.\n",
      "\n",
      "pprint()\n",
      "    Pretty-print a Python object to a stream [default is sys.stdout].\n",
      "\n",
      "saferepr()\n",
      "    Generate a 'standard' repr()-like value, but protect against recursive\n",
      "    data structures.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print(pprint.__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
